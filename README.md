# CS238 Final Project: Reinforcement Learning for Minichess Variants


<p align="center">
<img width="308" alt="Screen Shot 2023-02-18 at 4 55 16 PM" src="https://user-images.githubusercontent.com/57520931/219906266-023cf050-3194-4faa-bb24-a1c5f4378d9c.png">
</p>

In our project, we propose to apply reinforcement learning to chess variants, with a particular emphasis on so-called "minichess" rulesets. Chess is an oft-studied and widely popular game that is commonly framed as a sequential decision-making problem. Although the rules of chess are relatively simple, substantial uncertainty is generated by the sheer number of possible moves in any given chess position. Contemporary approaches to chess engine development have traditionally combined search algorithms with position evaluation heuristics. More recent engines, such as AlphaZero, have applied self-play reinforcement learning (trained using massive computational resources) to achieve equivalent and occasionally superior results. Minichess variants, such Silverman 4Ã—5, reduce the computational intractability of chess by shrinking the board and reducing the number of pieces. In our project, we apply reinforcement learning techniques to produce human-level results in minichess variants.
